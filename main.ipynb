{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d70262-80c0-4416-9976-aeef1ddd5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5be32d-3347-431d-8b9c-6b96272c3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopro.grammar import tensor\n",
    "from discopro.anaphora import connect_anaphora_on_top\n",
    "from lambeq import BobcatParser, NumpyModel, AtomicType, Rewriter, Dataset, QuantumTrainer, SPSAOptimizer , AtomicType, IQPAnsatz, RemoveCupsRewriter, UnifyCodomainRewriter, BinaryCrossEntropyLoss\n",
    "from lambeq.backend.grammar import Spider, Ty\n",
    "from lambeq.backend.quantum import Box, qubit, SelfConjugate, Ry, Diagram\n",
    "from contextuality.model import Model, Scenario, CyclicScenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1e8d19-f400-4baf-89fc-7b457aca2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cups = RemoveCupsRewriter()\n",
    "\n",
    "parser = BobcatParser()\n",
    "rewriter = Rewriter(['auxiliary',\n",
    "                     'connector',\n",
    "                     'coordination',\n",
    "                     'determiner',\n",
    "                     'object_rel_pronoun',\n",
    "                     'subject_rel_pronoun',\n",
    "                     'postadverb',\n",
    "                     'preadverb',\n",
    "                     'prepositional_phrase'])\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "P = AtomicType.PREPOSITIONAL_PHRASE \n",
    "\n",
    "ansatz = IQPAnsatz({N: 1, S: 1, P:1}, n_layers=1, n_single_qubit_params=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bcc9f45-31b4-4249-b743-56a74148690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2dig(sentence1: str, sentence2: str, pro: str, ref: str, mode='none'):\n",
    "    diagram1 = parser.sentence2diagram(sentence1)\n",
    "    diagram2 = parser.sentence2diagram(sentence2)\n",
    "    diagram = tensor(diagram1,diagram2)\n",
    "    \n",
    "    if mode == 'spider':\n",
    "        diagram = diagram >> Spider(S, 2, 1)\n",
    "    elif mode == 'box':\n",
    "        merger = UnifyCodomainRewriter(Ty('s'))\n",
    "        diagram = merger(diagram)\n",
    "        \n",
    "    pro_box_idx = next(i for i, box in enumerate(diagram.boxes) if box.name.casefold() == pro.casefold())\n",
    "    ref_box_idx = next(i for i, box in enumerate(diagram.boxes) if box.name.casefold() == ref.casefold())\n",
    "    final_diagram = connect_anaphora_on_top(diagram, pro_box_idx, ref_box_idx)\n",
    "    rewritten_diagram = rewriter(remove_cups(final_diagram)).normal_form()\n",
    "    return rewritten_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6fee0f0-5cd0-4e6e-b7aa-7a409d55c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(path: str, verbose=False):\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df[:10]\n",
    "    \n",
    "    if not os.path.exists(os.getcwd()+'/err_logs'):\n",
    "        os.mkdir(os.getcwd()+'/err_logs')\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    f = open(\"err_logs/log_\"+path.split('/')[-1].split('.')[-2]+'_'+timestamp+\".txt\",'w')\n",
    "    \n",
    "    circuits, labels, diagrams = [],[],[]\n",
    "    #selected_cols = [random.choice(['referent', 'wrong_referent']) for i in range(len(df))]\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), position=0, leave=True):\n",
    "        #ref = row[selected_cols[i]]\n",
    "        # label = [0,1] if selected_cols[i] == 'referent' else [1,0]\n",
    "        label = [[0.25, 0.25],[0.25, 0.25]]\n",
    "        sent1, sent2, pro, ref = row[['sentence1', 'sentence2', 'pronoun', 'referent']]\n",
    "\n",
    "        try:\n",
    "            diagram = sent2dig(sent1.strip(), sent2.strip(), pro.strip(), ref.strip())\n",
    "            diagrams.append(diagram)\n",
    "            circ = ansatz(diagram)\n",
    "            circuits.append(circ)\n",
    "            labels.append(label)\n",
    "        except Exception as err:\n",
    "            tqdm.write(f\"Error: {err}\".strip(), file=f)\n",
    "            if verbose:\n",
    "                tqdm.write(f\"Error: {err}\".strip(), file=sys.stderr)\n",
    "    f.close()\n",
    "    \n",
    "    return circuits, labels, diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ec4e10-1684-45d3-8f02-af63ed7f1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.55it/s]\n"
     ]
    }
   ],
   "source": [
    "train_circuits, train_labels, train_diagrams = gen_labels('dataset/original_data/train.csv')\n",
    "val_circuits, val_labels, val_diagrams = gen_labels('dataset/original_data/val.csv')\n",
    "test_circuits, test_labels, test_diagrams = gen_labels('dataset/original_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86c98d2b-33e9-4b5e-98ea-6a96b2d8cb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NumpyModel.from_diagrams(train_circuits + val_circuits + test_circuits, use_jit=False)\n",
    "loss = BinaryCrossEntropyLoss(use_jax=True)\n",
    "acc = lambda y_hat, y: np.sqrt(np.mean((y_hat-y)**2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9f6c331-e322-45f3-b283-73d7fc25e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = random.randint(0, 1000)\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "915a1ed8-d815-4d77-b9df-1aa35fbbc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)\n",
    "val_dataset = Dataset(val_circuits, val_labels, shuffle=True)\n",
    "test_dataset = Dataset(test_circuits, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e82c8913-89b6-4e91-8046-84ba8ca05da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(model,\n",
    "                         loss_function=loss,\n",
    "                         optimizer=SPSAOptimizer,\n",
    "                         epochs=EPOCHS,\n",
    "                         optim_hyperparams={'a': 0.1, 'c': 0.06, 'A': 0.01 * EPOCHS},\n",
    "                         evaluate_functions={\"err\": acc},\n",
    "                         evaluate_on_train=True,\n",
    "                         verbose='text', \n",
    "                         seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23eee093-adab-45d0-8082-99fc02e6028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-03_13_14_30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:    train/loss: 1.1192   valid/loss: 1.1773   train/err: 0.1678   valid/err: 0.1566\n",
      "Epoch 2:    train/loss: 0.9870   valid/loss: 1.4101   train/err: 0.1674   valid/err: 0.1707\n",
      "Epoch 3:    train/loss: 0.9530   valid/loss: 1.2091   train/err: 0.1739   valid/err: 0.1586\n",
      "Epoch 4:    train/loss: 0.9837   valid/loss: 1.4382   train/err: 0.1555   valid/err: 0.1697\n",
      "Epoch 5:    train/loss: 0.9521   valid/loss: 1.1242   train/err: 0.1369   valid/err: 0.1350\n",
      "Epoch 6:    train/loss: 0.9174   valid/loss: 1.1377   train/err: 0.1486   valid/err: 0.1616\n",
      "Epoch 7:    train/loss: 0.8519   valid/loss: 1.1717   train/err: 0.1406   valid/err: 0.1672\n",
      "Epoch 8:    train/loss: 0.9551   valid/loss: 1.1002   train/err: 0.1505   valid/err: 0.1495\n",
      "Epoch 9:    train/loss: 1.0021   valid/loss: 1.4796   train/err: 0.1675   valid/err: 0.1816\n",
      "Epoch 10:   train/loss: 1.0625   valid/loss: 1.4797   train/err: 0.1699   valid/err: 0.1835\n",
      "Epoch 11:   train/loss: 1.1152   valid/loss: 1.2572   train/err: 0.1934   valid/err: 0.1769\n",
      "Epoch 12:   train/loss: 0.9459   valid/loss: 1.1838   train/err: 0.1543   valid/err: 0.1788\n",
      "Epoch 13:   train/loss: 0.9508   valid/loss: 1.1345   train/err: 0.1872   valid/err: 0.1771\n",
      "Epoch 14:   train/loss: 0.8376   valid/loss: 1.1619   train/err: 0.1698   valid/err: 0.1810\n",
      "Epoch 15:   train/loss: 0.9128   valid/loss: 1.2060   train/err: 0.1875   valid/err: 0.1772\n",
      "Epoch 16:   train/loss: 0.9246   valid/loss: 1.1601   train/err: 0.1704   valid/err: 0.1632\n",
      "Epoch 17:   train/loss: 0.8399   valid/loss: 1.1608   train/err: 0.1626   valid/err: 0.1632\n",
      "Epoch 18:   train/loss: 0.8372   valid/loss: 1.1234   train/err: 0.1671   valid/err: 0.1596\n",
      "Epoch 19:   train/loss: 0.9343   valid/loss: 1.1431   train/err: 0.1635   valid/err: 0.1627\n",
      "Epoch 20:   train/loss: 0.8106   valid/loss: 1.0805   train/err: 0.1628   valid/err: 0.1548\n",
      "Epoch 21:   train/loss: 0.8298   valid/loss: 1.1010   train/err: 0.1401   valid/err: 0.1645\n",
      "Epoch 22:   train/loss: 0.8167   valid/loss: 1.0957   train/err: 0.1606   valid/err: 0.1622\n",
      "Epoch 23:   train/loss: 0.8479   valid/loss: 1.1029   train/err: 0.1649   valid/err: 0.1621\n",
      "Epoch 24:   train/loss: 0.9003   valid/loss: 1.1093   train/err: 0.1655   valid/err: 0.1637\n",
      "Epoch 25:   train/loss: 0.8715   valid/loss: 1.0781   train/err: 0.1584   valid/err: 0.1579\n",
      "Epoch 26:   train/loss: 0.8210   valid/loss: 1.0776   train/err: 0.1632   valid/err: 0.1577\n",
      "Epoch 27:   train/loss: 0.8771   valid/loss: 1.0704   train/err: 0.1640   valid/err: 0.1618\n",
      "Epoch 28:   train/loss: 0.8883   valid/loss: 1.0721   train/err: 0.1657   valid/err: 0.1628\n",
      "Epoch 29:   train/loss: 0.8594   valid/loss: 1.0873   train/err: 0.1812   valid/err: 0.1618\n",
      "Epoch 30:   train/loss: 0.8095   valid/loss: 1.0802   train/err: 0.1674   valid/err: 0.1608\n",
      "Epoch 31:   train/loss: 0.7635   valid/loss: 1.0784   train/err: 0.1417   valid/err: 0.1617\n",
      "Epoch 32:   train/loss: 0.8224   valid/loss: 1.0752   train/err: 0.1708   valid/err: 0.1623\n",
      "Epoch 33:   train/loss: 0.7962   valid/loss: 1.0717   train/err: 0.1534   valid/err: 0.1621\n",
      "Epoch 34:   train/loss: 0.8106   valid/loss: 1.0688   train/err: 0.1804   valid/err: 0.1609\n",
      "Epoch 35:   train/loss: 0.8159   valid/loss: 1.0691   train/err: 0.1494   valid/err: 0.1610\n",
      "Epoch 36:   train/loss: 0.7927   valid/loss: 1.0694   train/err: 0.1545   valid/err: 0.1612\n",
      "Epoch 37:   train/loss: 0.7790   valid/loss: 1.0693   train/err: 0.1576   valid/err: 0.1611\n",
      "Epoch 38:   train/loss: 0.7680   valid/loss: 1.0667   train/err: 0.1429   valid/err: 0.1608\n",
      "Epoch 39:   train/loss: 0.8047   valid/loss: 1.0706   train/err: 0.1694   valid/err: 0.1616\n",
      "Epoch 40:   train/loss: 0.7742   valid/loss: 1.0729   train/err: 0.1537   valid/err: 0.1603\n",
      "Epoch 41:   train/loss: 0.7824   valid/loss: 1.0729   train/err: 0.1503   valid/err: 0.1604\n",
      "Epoch 42:   train/loss: 0.7923   valid/loss: 1.0756   train/err: 0.1741   valid/err: 0.1574\n",
      "Epoch 43:   train/loss: 0.7836   valid/loss: 1.0770   train/err: 0.1524   valid/err: 0.1577\n",
      "Epoch 44:   train/loss: 0.7862   valid/loss: 1.0780   train/err: 0.1530   valid/err: 0.1579\n",
      "Epoch 45:   train/loss: 0.7831   valid/loss: 1.0767   train/err: 0.1537   valid/err: 0.1582\n",
      "Epoch 46:   train/loss: 0.8043   valid/loss: 1.0770   train/err: 0.1605   valid/err: 0.1573\n",
      "Epoch 47:   train/loss: 0.7331   valid/loss: 1.0768   train/err: 0.1436   valid/err: 0.1574\n",
      "Epoch 48:   train/loss: 0.7910   valid/loss: 1.0761   train/err: 0.1465   valid/err: 0.1576\n",
      "Epoch 49:   train/loss: 0.7708   valid/loss: 1.0762   train/err: 0.1527   valid/err: 0.1576\n",
      "Epoch 50:   train/loss: 0.7168   valid/loss: 1.0759   train/err: 0.1492   valid/err: 0.1576\n",
      "Epoch 51:   train/loss: 0.7613   valid/loss: 1.0761   train/err: 0.1520   valid/err: 0.1578\n",
      "Epoch 52:   train/loss: 0.8249   valid/loss: 1.0743   train/err: 0.1626   valid/err: 0.1576\n",
      "Epoch 53:   train/loss: 0.7571   valid/loss: 1.0748   train/err: 0.1435   valid/err: 0.1576\n",
      "Epoch 54:   train/loss: 0.8134   valid/loss: 1.0706   train/err: 0.1786   valid/err: 0.1580\n",
      "Epoch 55:   train/loss: 0.7929   valid/loss: 1.0742   train/err: 0.1531   valid/err: 0.1582\n",
      "Epoch 56:   train/loss: 0.7858   valid/loss: 1.0760   train/err: 0.1483   valid/err: 0.1583\n",
      "Epoch 57:   train/loss: 0.8175   valid/loss: 1.0741   train/err: 0.1523   valid/err: 0.1578\n",
      "Epoch 58:   train/loss: 0.7711   valid/loss: 1.0757   train/err: 0.1593   valid/err: 0.1580\n",
      "Epoch 59:   train/loss: 0.7667   valid/loss: 1.0726   train/err: 0.1649   valid/err: 0.1588\n",
      "Epoch 60:   train/loss: 0.7751   valid/loss: 1.0693   train/err: 0.1629   valid/err: 0.1582\n",
      "Epoch 61:   train/loss: 0.7958   valid/loss: 1.0732   train/err: 0.1577   valid/err: 0.1573\n",
      "Epoch 62:   train/loss: 0.7360   valid/loss: 1.0733   train/err: 0.1388   valid/err: 0.1571\n",
      "Epoch 63:   train/loss: 0.7443   valid/loss: 1.0734   train/err: 0.1500   valid/err: 0.1571\n",
      "Epoch 64:   train/loss: 0.8341   valid/loss: 1.0748   train/err: 0.1565   valid/err: 0.1566\n",
      "Epoch 65:   train/loss: 0.7682   valid/loss: 1.0740   train/err: 0.1558   valid/err: 0.1563\n",
      "Epoch 66:   train/loss: 0.7696   valid/loss: 1.0744   train/err: 0.1540   valid/err: 0.1563\n",
      "Epoch 67:   train/loss: 0.7346   valid/loss: 1.0764   train/err: 0.1414   valid/err: 0.1566\n",
      "Epoch 68:   train/loss: 0.7477   valid/loss: 1.0768   train/err: 0.1490   valid/err: 0.1562\n",
      "Epoch 69:   train/loss: 0.7639   valid/loss: 1.0821   train/err: 0.1401   valid/err: 0.1570\n",
      "Epoch 70:   train/loss: 0.7504   valid/loss: 1.0814   train/err: 0.1388   valid/err: 0.1570\n",
      "Epoch 71:   train/loss: 0.8166   valid/loss: 1.0775   train/err: 0.1625   valid/err: 0.1562\n",
      "Epoch 72:   train/loss: 0.7530   valid/loss: 1.0716   train/err: 0.1233   valid/err: 0.1557\n",
      "Epoch 73:   train/loss: 0.8433   valid/loss: 1.0726   train/err: 0.1836   valid/err: 0.1559\n",
      "Epoch 74:   train/loss: 0.7618   valid/loss: 1.0729   train/err: 0.1473   valid/err: 0.1558\n",
      "Epoch 75:   train/loss: 0.7676   valid/loss: 1.0722   train/err: 0.1648   valid/err: 0.1558\n",
      "Epoch 76:   train/loss: 0.7546   valid/loss: 1.0722   train/err: 0.1533   valid/err: 0.1558\n",
      "Epoch 77:   train/loss: 0.8446   valid/loss: 1.0738   train/err: 0.1494   valid/err: 0.1568\n",
      "Epoch 78:   train/loss: 0.8077   valid/loss: 1.0748   train/err: 0.1694   valid/err: 0.1576\n",
      "Epoch 79:   train/loss: 0.8480   valid/loss: 1.0756   train/err: 0.1463   valid/err: 0.1557\n",
      "Epoch 80:   train/loss: 0.7872   valid/loss: 1.0800   train/err: 0.1621   valid/err: 0.1559\n",
      "Epoch 81:   train/loss: 0.7611   valid/loss: 1.0811   train/err: 0.1492   valid/err: 0.1558\n",
      "Epoch 82:   train/loss: 0.7816   valid/loss: 1.0820   train/err: 0.1667   valid/err: 0.1560\n",
      "Epoch 83:   train/loss: 0.7626   valid/loss: 1.0822   train/err: 0.1512   valid/err: 0.1560\n",
      "Epoch 84:   train/loss: 0.7699   valid/loss: 1.0825   train/err: 0.1629   valid/err: 0.1561\n",
      "Epoch 85:   train/loss: 0.8101   valid/loss: 1.0822   train/err: 0.1739   valid/err: 0.1562\n",
      "Epoch 86:   train/loss: 0.7798   valid/loss: 1.0815   train/err: 0.1500   valid/err: 0.1558\n",
      "Epoch 87:   train/loss: 0.7459   valid/loss: 1.0812   train/err: 0.1517   valid/err: 0.1558\n",
      "Epoch 88:   train/loss: 0.7849   valid/loss: 1.0829   train/err: 0.1593   valid/err: 0.1560\n",
      "Epoch 89:   train/loss: 0.7669   valid/loss: 1.0834   train/err: 0.1566   valid/err: 0.1560\n",
      "Epoch 90:   train/loss: 0.7545   valid/loss: 1.0834   train/err: 0.1583   valid/err: 0.1560\n",
      "Epoch 91:   train/loss: 0.7786   valid/loss: 1.0813   train/err: 0.1693   valid/err: 0.1557\n",
      "Epoch 92:   train/loss: 0.7781   valid/loss: 1.0833   train/err: 0.1538   valid/err: 0.1563\n",
      "Epoch 93:   train/loss: 0.7609   valid/loss: 1.0832   train/err: 0.1501   valid/err: 0.1564\n",
      "Epoch 94:   train/loss: 0.7490   valid/loss: 1.0819   train/err: 0.1474   valid/err: 0.1561\n",
      "Epoch 95:   train/loss: 0.7639   valid/loss: 1.0805   train/err: 0.1647   valid/err: 0.1559\n",
      "Epoch 96:   train/loss: 0.7760   valid/loss: 1.0805   train/err: 0.1599   valid/err: 0.1558\n",
      "Epoch 97:   train/loss: 0.8417   valid/loss: 1.0866   train/err: 0.1540   valid/err: 0.1560\n",
      "Epoch 98:   train/loss: 0.8165   valid/loss: 1.0871   train/err: 0.1636   valid/err: 0.1547\n",
      "Epoch 99:   train/loss: 0.7814   valid/loss: 1.0864   train/err: 0.1596   valid/err: 0.1547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.14306237778219807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100:  train/loss: 0.7508   valid/loss: 1.0864   train/err: 0.1533   valid/err: 0.1547\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning parameters: \"+datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\"))\n",
    "trainer.fit(train_dataset, val_dataset, eval_interval=1, log_interval=1)\n",
    "test_acc = acc(model(test_dataset.data), test_dataset.targets)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3072438-8662-426e-9150-4254e1fbcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainer: QuantumTrainer, EPOCH_ARR: [int], BATCH_ARR: [int], SEED_N: int, train_dataset: Dataset, val_dataset: Dataset, test_dataset: Dataset):\n",
    "    SEEDS = random.sample(range(1000), SEED_N)\n",
    "    trainer.verbose = 'supress'\n",
    "    model = trainer.model\n",
    "    \n",
    "    print(\"%0s %23s %7s %7s  %12s\" % (\"Time\",\"Epochs\",\"Batch\",\"Seed\",\"Accuracy\"))\n",
    "    for EPOCHS in EPOCH_ARR:\n",
    "        for BATCH_SIZE in BATCH_ARR:\n",
    "            for SEED in SEEDS:\n",
    "                trainer.epochs = EPOCHS\n",
    "                trainer.optim_hyperparams = {'a': 0.1, 'c': 0.06, 'A': 0.01 * EPOCHS}\n",
    "                train_dataset.batch_size = BATCH_SIZE\n",
    "                time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "                print(\"%0s %8s %7s %7s\" % (time, EPOCHS, BATCH_SIZE, SEED), end='')\n",
    "                trainer.fit(train_dataset, val_dataset, eval_interval=1, log_interval=1)\n",
    "                test_acc = acc(model(test_dataset.data), test_dataset.targets)\n",
    "                print(\"%14s\" % (round(test_acc, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d748435a-6719-44b7-a398-17679514e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_scenario:\n",
    "    def __init__(self, scenario, data, model):\n",
    "        self.scenario = scenario\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        try:\n",
    "            self.model.initialise_weights()\n",
    "        except Exception as err:\n",
    "            print(\"Model is not valid or none provided: \", err)\n",
    "        self.emp_models = []\n",
    "\n",
    "    def gen_emp(self, s1, s2, p, n):\n",
    "        try:\n",
    "            diag = ansatz(sent2dig(s1, s2, p, n))\n",
    "        except Exception as err:\n",
    "            tqdm.write(f\"Error: {err}\".strip(), file=sys.stderr)\n",
    "            return None\n",
    "        diagXX = diag.apply_gate(Ry(0),0).apply_gate(Ry(np.pi/8),1)\n",
    "        diagXZ = diag.apply_gate(Ry(0),0).apply_gate(Ry(3*np.pi/8),1)\n",
    "        diagZX = diag.apply_gate(Ry(np.pi/4),0).apply_gate(Ry(np.pi/8),1)\n",
    "        diagZZ = diag.apply_gate(Ry(np.pi/4),0).apply_gate(Ry(3*np.pi/8),1)\n",
    "        dist = [self.model.get_diagram_output([diagXX])[0].flatten()]\n",
    "        dist.append(self.model.get_diagram_output([diagXZ])[0].flatten())\n",
    "        dist.append(self.model.get_diagram_output([diagZX])[0].flatten())\n",
    "        dist.append(self.model.get_diagram_output([diagZZ])[0].flatten())\n",
    "        #dist = self.model.get_diagram_output([diagXX, diagXZ, diagZX, diagZZ])\n",
    "        emp_model = Model(self.scenario, dist)\n",
    "        return emp_model\n",
    "\n",
    "    def get_models(self):\n",
    "        for _, row in tqdm(self.data.iterrows(), total=len(self.data)):\n",
    "            emp_model = self.gen_emp(*row[['sentence1','sentence2','pronoun','referent']])\n",
    "            if emp_model:\n",
    "                self.emp_models.append(emp_model)\n",
    "        return self.emp_models\n",
    "\n",
    "    def plot_cnxt(self):\n",
    "        sf, di = [], []\n",
    "        for mod in self.emp_models:\n",
    "            sf.append(mod.signalling_fraction())\n",
    "            di.append(mod.CbD_direct_influence())\n",
    "        plt.scatter(sf, di)\n",
    "        plt.axhline(y=2, color='g', linestyle='-')\n",
    "        plt.axvline(x=1/6, color='g', linestyle='-')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "013ca08d-d811-4182-b35e-f5f3c85fcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_scenario(scenario=CyclicScenario(['a','b','A','B'],2), \n",
    "                    data=pd.read_csv('dataset/original_data/test.csv'),\n",
    "                    model=NumpyModel.from_checkpoint('runs/Jul02_12-46-52_smew.cs.ucl.ac.uk/best_model.lt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82585308-ff27-4377-839e-6aca51be00ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c7e1d-cfaa-4c5b-a893-13ae425e2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.plot_cnxt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnlp",
   "language": "python",
   "name": "qnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
