{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "02d70262-80c0-4416-9976-aeef1ddd5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os, sys, pickle\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from lambeq import NumpyModel, AtomicType, IQPAnsatz\n",
    "from lambeq.backend.quantum import Ry, Diagram, Bra\n",
    "from contextuality.model import Model, Scenario, CyclicScenario\n",
    "from util import sent2dig\n",
    "import tensornetwork as tn\n",
    "from scipy.linalg import logm, sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9683490e-f323-4bf6-b511-845ea6f7b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModel(NumpyModel):\n",
    "    def __init__(self, use_jit: bool = False) -> None:\n",
    "        super().__init__(use_jit)\n",
    "\n",
    "    def get_output_state(self, diagrams):\n",
    "        diagrams = self._fast_subs(diagrams, self.weights)\n",
    "        results = []\n",
    "        for d in diagrams:\n",
    "            assert isinstance(d, Diagram)\n",
    "            result = tn.contractors.auto(*d.to_tn()).tensor\n",
    "            result = np.array(result).flatten()\n",
    "            result = np.sqrt(result/sum(abs(result)))\n",
    "            results.append(result)\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7f1cee9c-cbdd-4081-8ba8-a84d699d649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'disjoint_uncut': 'runs/disjoint_uncut_130E/best_model.lt', \n",
    "          'disjoint_cut': 'runs/disjoint_cut_140E/best_model.lt',\n",
    "          'spider_uncut': 'runs/spider_uncut_200E/best_model.lt', \n",
    "          'spider_cut': 'runs/Jul15_13-17-36_smew.cs.ucl.ac.uk/best_model.lt'}\n",
    "\n",
    "diagrams = {'disjoint_uncut': 'dataset/diagrams/disjoint_uncut.pkl',\n",
    "            'disjoint_cut': 'dataset/diagrams/disjoint_cut.pkl',\n",
    "            'spider_uncut': 'dataset/diagrams/spider_uncut.pkl',\n",
    "            'spider_cut': 'dataset/diagrams/spider_cut.pkl'}\n",
    "\n",
    "data = {'disjoint_uncut': 'dataset/contextuality_data/scenario442_disjoint_uncut.csv',\n",
    "        'disjoint_cut': 'dataset/contextuality_data/scenario442_disjoint_cut.csv',\n",
    "        'spider_uncut': 'dataset/contextuality_data/scenario422_spider_uncut.csv',\n",
    "        'spider_cut': 'dataset/contextuality_data/scenario442_spider_cut.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc1e8d19-f400-4baf-89fc-7b457aca2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "P = AtomicType.PREPOSITIONAL_PHRASE\n",
    "\n",
    "ansatz = IQPAnsatz({N: 1, S: 1, P:1}, n_layers=1, n_single_qubit_params=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d748435a-6719-44b7-a398-17679514e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_processor:\n",
    "    def __init__(self, scenario: Scenario, model_path: str=None):\n",
    "        self.scenario = scenario # Measurement scenario modelling the schema\n",
    "\n",
    "        # Data\n",
    "        self.data = pd.DataFrame(columns=[\"Sentence\", \"CF\", \"SF\", \"CbD\", \"DI\", \"Violation\", \"Distribution\"])\n",
    "        self.diagrams = []\n",
    "        self.sentences = []\n",
    "            \n",
    "        if model_path: # Model is a NumpyModel with learnt parameters of ansatz circuits\n",
    "            self.model = QModel.from_checkpoint(model_path)\n",
    "            self.model.initialise_weights()\n",
    "        else:\n",
    "            self.model = None\n",
    "\n",
    "        # Measurement basis used in max violation CHSH experiment with their matrix representations\n",
    "        self.bases = {'a':Ry(0), 'A':Ry(np.pi/4), 'b':Ry(np.pi/8), 'B':Ry(3*np.pi/8)}\n",
    "        self.pairs = {'ab': np.kron(Ry(0).array, Ry(np.pi/8).array),\n",
    "                      'aB': np.kron(Ry(0).array, Ry(3*np.pi/8).array),\n",
    "                      'Ab': np.kron(Ry(np.pi/4).array, Ry(np.pi/8).array),\n",
    "                      'AB': np.kron(Ry(np.pi/4).array, Ry(3*np.pi/8).array)}\n",
    "\n",
    "    def load_file(self, path: str) -> None | pd.DataFrame | zip:\n",
    "        if not path:\n",
    "            return\n",
    "        elif os.path.splitext(path)[-1] == '.csv':\n",
    "            return pd.read_csv(path)\n",
    "        elif os.path.splitext(path)[-1] == '.pkl':\n",
    "            file = open(path, 'rb')\n",
    "            data =  pickle.load(file)\n",
    "            file.close()\n",
    "            return data\n",
    "        else:\n",
    "            print(\"Provided file doesn't match a supported type.\")\n",
    "            return\n",
    "\n",
    "    def load_model(self, path: str, variant: str=None) -> None:\n",
    "        self.model = NumpyModel.from_checkpoint(model_path)\n",
    "\n",
    "    def get_data(self, path: str) -> None:\n",
    "        if not path:\n",
    "            return\n",
    "        self.data = self.load_file(path)\n",
    "\n",
    "    def get_diagrams(self, path: str, con=True) -> None:\n",
    "        if not path:\n",
    "            return\n",
    "        \n",
    "        schema_data = self.load_file(path)\n",
    "        if os.path.splitext(path)[-1] == '.pkl':\n",
    "            self.sentences, self.diagrams = zip(*schema_data)\n",
    "            self.sentences = list(self.sentences)\n",
    "            self.diagrams = list(self.diagrams)\n",
    "            return\n",
    "            \n",
    "        for _, row in tqdm(schema_data.iterrows(), total=len(schema_data)):\n",
    "            try:\n",
    "                s1, s2, pro, ref = row[['sentence1','sentence2','pronoun','referent']]\n",
    "                self.diagrams.append(ansatz(sent2dig(s1, s2, pro, ref, con=con)))\n",
    "                self.sentences.append(s1 + '. ' + s2 + '.')\n",
    "            except Exception as err:\n",
    "                tqdm.write(f\"Error: {err}\".strip(), file=sys.stderr)\n",
    "        f = open('dataset/sent_circ_pairs'+'_'+str(len(self.diagrams))+'_'+datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")+'.pkl', 'wb')\n",
    "        pickle.dump(list(zip(self.sentences, self.diagrams)), f)\n",
    "        f.close()\n",
    "\n",
    "    def get_emp_model(self, diag: Diagram) -> Model:\n",
    "        diag_ab = diag.apply_gate(self.bases['a'],0).apply_gate(self.bases['b'],1)\n",
    "        diag_aB = diag.apply_gate(self.bases['a'],0).apply_gate(self.bases['B'],1)\n",
    "        diag_Ab = diag.apply_gate(self.bases['A'],0).apply_gate(self.bases['b'],1)\n",
    "        diag_AB = diag.apply_gate(self.bases['A'],0).apply_gate(self.bases['B'],1)\n",
    "\n",
    "        pr_dist = self.model.get_diagram_output([diag_ab, diag_aB, diag_Ab, diag_AB])\n",
    "        pr_dist = np.reshape(pr_dist, (4,4))\n",
    "        return Model(self.scenario, pr_dist)\n",
    "\n",
    "    def calc_violation(self, state: np.array) -> float:\n",
    "        expectations = [np.matmul(state, np.matmul(self.pairs[ops], state)) for ops in list(self.pairs.keys())]\n",
    "        res = 0.0 + 0.0j\n",
    "        for i in range(4):\n",
    "            cur = abs(sum(expectations) - 2*expectations[i])\n",
    "            #possible_vals.append(res)\n",
    "            res = max(res, cur)\n",
    "        return res\n",
    "\n",
    "    def bipartide_partial_trace(self, dense_mat):\n",
    "        # Compute reduced density matrix for a bipartide quantum system\n",
    "        n_dim = dense_mat.shape[0]//2\n",
    "        id_mat = np.identity(n_dim)\n",
    "    \n",
    "        res = np.zeros((n_dim, n_dim))\n",
    "        for base in id_mat:\n",
    "            bra = np.kron(id_mat, base)\n",
    "            ket = np.kron(id_mat, base).T\n",
    "            res = res + np.matmul(np.matmul(bra, dense_mat), ket)\n",
    "        return res\n",
    "\n",
    "    def log_mat(self, mat): # Matrix logarithm via eigendecomposition\n",
    "        evals, emat = np.linalg.eig(mat) # Get matrix V of eigenvectors of input matrix A\n",
    "        emat_inv = np.linalg.inv(emat) # Get inverse of matrix V\n",
    "        matp = emat @ mat @ emat_inv # Compute A' with a diagonal of eigenvalues tr(A') = evals\n",
    "        np.fill_diagonal(matp, np.log(matp.diagonal())) # Element wise natural log of diagonal\n",
    "        return emat_inv @ matp @ emat # Change basis back\n",
    "\n",
    "    def calc_vne(self, dense_mat):\n",
    "        evals = np.linalg.eigvals(mat)\n",
    "        evals = evals[np.abs(evals) > 1e-12]\n",
    "        ent = -np.sum(evals * np.log(evals))\n",
    "        if ent > 1e-12:\n",
    "            return ent\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def qrel_ent(self, mat1, mat2):\n",
    "        evals1 = self.eigen_decompose(mat1)\n",
    "        evals2 = self.eigen_decompose(mat2)\n",
    "        return np.sum(evals1*(evals1 - evals2))\n",
    "\n",
    "    def get_dense_mat(self, state, tol=1e-12):\n",
    "        dense_mat = np.outer(state, np.conjugate(state))\n",
    "        dense_mat.real[abs(dense_mat.real) < tol] = 0.0\n",
    "        dense_mat.imag[abs(dense_mat.imag) < tol] = 0.0\n",
    "        return dense_mat\n",
    "    \n",
    "    def gen_data(self) -> None:\n",
    "        data_dict = {'Sentence':[], 'CF':[], 'SF':[], 'CbD':[], 'DI':[], 'Violation':[], 'Distribution': []}\n",
    "        for diagram, sentence in tqdm(zip(self.diagrams, self.sentences), total=len(self.diagrams)):\n",
    "            try:\n",
    "                cur_emp_model = self.get_emp_model(diagram)\n",
    "                \n",
    "                data_dict['CF'].append(cur_emp_model.signalling_fraction())\n",
    "                data_dict['SF'].append(cur_emp_model.contextual_fraction())\n",
    "                data_dict['CbD'].append(cur_emp_model.CbD_measure())\n",
    "                data_dict['DI'].append(cur_emp_model.CbD_direct_influence())\n",
    "                data_dict['Distribution'].append(cur_emp_model._distributions)\n",
    "                state = self.model.get_output_state([diagram])[0]\n",
    "                data_dict['Violation'].append(self.calc_violation(state))\n",
    "                data_dict['Sentence'].append(sentence)\n",
    "            except Exception as err:\n",
    "                tqdm.write(f\"Error: {err}\".strip(), file=sys.stderr)\n",
    "        self.data = pd.DataFrame(data_dict)\n",
    "        self.data.to_csv('dataset/scenario442_' + str(len(self.diagrams)) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\") + '.csv')\n",
    "\n",
    "    def plot_cnxt(self, title: str, save: bool=True) -> None:\n",
    "        cf = self.data['CF'].to_numpy()\n",
    "        sf = self.data['SF'].to_numpy()\n",
    "        di = self.data['DI'].to_numpy()\n",
    "        cmap = plt.get_cmap('viridis_r')\n",
    "        cmap.set_under('red')\n",
    "        scat = plt.scatter(x=cf, y=di, c=sf, cmap=cmap, vmax=1, vmin=1/6)\n",
    "        plt.axvline(x=1/6, color='r', linestyle='-')\n",
    "        plt.axhline(y=2, color='r', linestyle='-')\n",
    "        plt.text(x=1/6+0.05,y=5,s='Sheaf Contextual')\n",
    "        plt.text(x=0.7,y=1.5,s='CbD Contextual')\n",
    "        plt.xlabel('Contextual Fraction')\n",
    "        plt.ylabel('Direct Influence')\n",
    "        plt.colorbar(label='Signalling Fraction', extend='min')\n",
    "        plt.title(title)\n",
    "        scat.set_alpha(0.5)\n",
    "        scat.cmap.set_over('red')\n",
    "        if save:\n",
    "            plt.savefig('figures/' + title + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\"))\n",
    "        plt.show()\n",
    "\n",
    "    def test_plot(self, title: str, save: bool=True, x=[], y=[], z=[], vmin=0, vmax=0,\n",
    "                 x_label='x', y_label='y', z_label='z') -> None:\n",
    "        if vmax==0:\n",
    "            vmax=max(z)\n",
    "\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        cmap.set_under('red')\n",
    "        scat = plt.scatter(x=x, y=y, c=z, alpha=1, vmax=vmax, vmin=vmin, cmap=cmap)\n",
    "\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.colorbar(label=z_label, extend='min')\n",
    "        plt.title(title)\n",
    "        scat.set_alpha(0.5)\n",
    "        scat.cmap.set_under('red')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "683618a1-ff77-4334-bbda-ee22f63e8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_processor(scenario=CyclicScenario(['a','b','A','B'],2),\n",
    "                      model_path=models['disjoint_uncut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb9f5640-ec28-4a77-b82f-f904ea46a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_data(data['disjoint_uncut'])\n",
    "test.get_diagrams(diagrams['disjoint_uncut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0c70e5e-d473-4e39-9ef0-2bd3f27af6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.data[\"CF\"]\n",
    "z = test.data[\"SF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3853135b-4cf4-4d01-8074-7fe9f4b39cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3057/3057 [03:38<00:00, 14.02it/s]\n"
     ]
    }
   ],
   "source": [
    "eoe = []\n",
    "qre = []\n",
    "tol = 1e-12\n",
    "for diagram in tqdm(test.diagrams):\n",
    "    try:\n",
    "        #dist = test.model.get_diagram_output([diagram])[0].flatten()\n",
    "        #state = np.sqrt(dist)\n",
    "        state = test.model.get_output_state([diagram])[0]\n",
    "        dense_mat = test.get_dense_mat(state)\n",
    "        reduced_dense_mat = test.bipartide_partial_trace(dense_mat)\n",
    "        eoe.append(test.calc_vne(reduced_dense_mat))\n",
    "\n",
    "        diag1 = diagram.apply_gate(Bra(0),0)\n",
    "        diag2 = diagram.apply_gate(Bra(0),1)\n",
    "        state1 = test.model.get_output_state([diag1])[0]\n",
    "        state2 = test.model.get_output_state([diag2])[0]\n",
    "        mat1 = test.get_dense_mat(state1)\n",
    "        mat2 = test.get_dense_mat(state2)\n",
    "        qre.append(test.qrel_ent(mat1, mat2))\n",
    "    except Exception as err:\n",
    "        tqdm.write(f\"Error: {err}\".strip(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "657e74ab-2f0d-4d97-a08d-03fffc8c556d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 8 is different from 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m],dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcdouble)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m dense_mat \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mget_dense_mat(state)\n\u001b[0;32m----> 3\u001b[0m reduced_dense_mat \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mbipartide_partial_trace(dense_mat)\n\u001b[1;32m      4\u001b[0m discut\u001b[38;5;241m.\u001b[39mcalc_vne(reduced_dense_mat)\n",
      "Cell \u001b[0;32mIn[127], line 95\u001b[0m, in \u001b[0;36mdata_processor.bipartide_partial_trace\u001b[0;34m(self, dense_mat)\u001b[0m\n\u001b[1;32m     93\u001b[0m     bra \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mkron(id_mat,vec)\n\u001b[1;32m     94\u001b[0m     ket \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mkron(id_mat, vec)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 95\u001b[0m     res \u001b[38;5;241m=\u001b[39m res \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mmatmul(bra, dense_mat), ket)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 8 is different from 16)"
     ]
    }
   ],
   "source": [
    "state = np.array([1,0,0,0,0,0,0,1],dtype=np.cdouble)*np.sqrt(1/2)\n",
    "dense_mat = test.get_dense_mat(state)\n",
    "reduced_dense_mat = test.bipartide_partial_trace(dense_mat)\n",
    "discut.calc_vne(reduced_dense_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "25a5cb98-4059-4949-8aa1-7a4b954d1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([1,0,0,1],dtype=np.cdouble)*np.sqrt(1/2)\n",
    "dense_mat = np.outer(state, state)\n",
    "dims_a = int(2**(np.floor(np.log2(dense_mat.shape[0])/2)))\n",
    "dims_b = int(2**(np.ceil(np.log2(dense_mat.shape[0])/2)))\n",
    "id_mat_a = np.identity(dims_a)\n",
    "id_mat_b = np.identity(dims_b)\n",
    "\n",
    "dense_a = np.zeros((dims_a, dims_a))\n",
    "dense_b = np.zeros((dims_b, dims_b))\n",
    "\n",
    "for base in id_mat_b:\n",
    "    bra = np.kron(id_mat_a, base)\n",
    "    ket = np.kron(id_mat_a, base).T\n",
    "    dense_a = dense_a + np.matmul(np.matmul(bra, dense_mat), ket)\n",
    "\n",
    "for base in id_mat_a:\n",
    "    bra = np.kron(id_mat_b, base)\n",
    "    ket = np.kron(id_mat_b, base).T\n",
    "    dense_b = dense_b + np.matmul(np.matmul(bra, dense_mat), ket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "02ef0cbd-75e6-49dd-8897-2e59c422aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mat(mat): # Matrix logarithm via eigendecomposition\n",
    "    evals, emat = np.linalg.eig(mat) # Get matrix V of eigenvectors of input matrix A\n",
    "    emat_inv = np.linalg.inv(emat) # Get inverse of matrix V\n",
    "    matp = emat @ mat @ emat_inv # Compute A' with a diagonal of eigenvalues tr(A') = evals\n",
    "    np.fill_diagonal(matp, np.log(matp.diagonal())) # Element wise natural log of diagonal\n",
    "    return emat_inv @ matp @ emat # Change basis back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b4fb2c66-ce09-4754-90ae-11db2d2292e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6931471805599452-0j)\n"
     ]
    }
   ],
   "source": [
    "print(-np.trace(dense_a @ log_mat(dense_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c9774d03-cc77-435a-9be9-54c2f2559af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = np.linalg.eigvals(dense_a)\n",
    "evals = evals[np.abs(evals) > 1e-12]\n",
    "ent_a = -np.sum(evals * np.log(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "1e844bf6-c1c3-4b51-9785-0a844436c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = np.linalg.eigvals(dense_b)\n",
    "evals = evals[np.abs(evals) > 1e-12]\n",
    "ent_b = -np.sum(evals * np.log(evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e33b84f0-8553-4a58-98a1-602edadc07fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6931471805599452-0j)\n",
      "(0.6931471805599452-0j)\n"
     ]
    }
   ],
   "source": [
    "print(ent_a)\n",
    "print(ent_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e442b75-98a1-4a40-940d-3d3ec4d642a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnlp",
   "language": "python",
   "name": "qnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
