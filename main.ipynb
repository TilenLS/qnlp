{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d70262-80c0-4416-9976-aeef1ddd5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "from discopro.grammar import tensor\n",
    "from lambeq import BobcatParser, NumpyModel, AtomicType, Rewriter, Dataset, QuantumTrainer, SPSAOptimizer , AtomicType, IQPAnsatz, RemoveCupsRewriter\n",
    "from lambeq.backend.grammar import Spider\n",
    "from lambeq.rewrite import UnifyCodomainRewriter\n",
    "from lambeq.backend.drawing import draw\n",
    "from lambeq.backend.grammar import Ty\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "from discopro.anaphora import connect_anaphora_on_top\n",
    "from contextuality.model import Model, Scenario, CyclicScenario\n",
    "from lambeq.backend.quantum import Box, qubit, SelfConjugate, Ry, Diagram\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1e8d19-f400-4baf-89fc-7b457aca2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cups = RemoveCupsRewriter()\n",
    "\n",
    "parser = BobcatParser()\n",
    "rewriter = Rewriter(['auxiliary',\n",
    "                     'connector',\n",
    "                     'coordination',\n",
    "                     'determiner',\n",
    "                     'object_rel_pronoun',\n",
    "                     'subject_rel_pronoun',\n",
    "                     'postadverb',\n",
    "                     'preadverb',\n",
    "                     'prepositional_phrase'])\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "P = AtomicType.PREPOSITIONAL_PHRASE \n",
    "\n",
    "ansatz = IQPAnsatz({N: 1, S: 1, P:1}, n_layers=1, n_single_qubit_params=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106e1d89-d3ff-4149-bcfb-08e0acfa311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diagram(diagram, pro, ref):\n",
    "\n",
    "    pro_box_idx = next(i for i, box in enumerate(diagram.boxes) if box.name.casefold() == pro.casefold())\n",
    "    ref_box_idx = next(i for i, box in enumerate(diagram.boxes) if box.name.casefold() == ref.casefold())\n",
    "    final_diagram = connect_anaphora_on_top(diagram, pro_box_idx, ref_box_idx)\n",
    "    rewritten_diagram = rewriter(remove_cups(final_diagram)).normal_form()\n",
    "    return rewritten_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcc9f45-31b4-4249-b743-56a74148690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2dig(sentence1: str, sentence2: str, pro: str, ref: str):\n",
    "    diagram1 = parser.sentence2diagram(sentence1)\n",
    "    diagram2 = parser.sentence2diagram(sentence2)\n",
    "    diagram = tensor(diagram1,diagram2)\n",
    "    #diagram = diagram >> Spider(S, 2, 1)\n",
    "    diagram = generate_diagram(diagram, pro, ref)\n",
    "    #merger = UnifyCodomainRewriter(Ty('s'))\n",
    "    #diagram = merger(diagram)\n",
    "    return diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6fee0f0-5cd0-4e6e-b7aa-7a409d55c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(df: pd.DataFrame):\n",
    "    circuits, labels, diagrams = [],[],[]\n",
    "    #selected_cols = [random.choice(['referent', 'wrong_referent']) for i in range(len(df))]\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), position=0, leave=True):\n",
    "        #ref = row[selected_cols[i]]\n",
    "        # label = [[0.25, 0.25],[0.25, 0.25]] if selected_cols[i] == 'referent' else [[0.25, 0.25],[0.25, 0.25]]\n",
    "        # sent1, sent2, pro = row[['sentence1', 'sentence2', 'pronoun']]\n",
    "        label = [[0.25, 0.25],[0.25, 0.25]]\n",
    "        sent1, sent2, pro, ref = row[['sentence1', 'sentence2', 'pronoun', 'referent']]\n",
    "\n",
    "        try:\n",
    "            diagram = sent2dig(sent1.strip(), sent2.strip(), pro.strip(), ref.strip())\n",
    "            diagrams.append(diagram)\n",
    "            circ = ansatz(diagram)\n",
    "            circuits.append(circ)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error: {e}\".strip(), file=sys.stderr)\n",
    "    return circuits, labels, diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022d5281-5a86-40ac-94a9-e3c3233982f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/original_data/train.csv', index_col=0)\n",
    "df_val = pd.read_csv('dataset/original_data/val.csv', index_col=0)\n",
    "df_test = pd.read_csv('dataset/original_data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78ec4e10-1684-45d3-8f02-af63ed7f1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.45it/s]\n",
      "Error: Diagram 0 (cod=n @ n.r @ n @ n) does not compose with diagram 1 (dom=n @ p.r @ n)                                                                 \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.72it/s]\n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_circuits, train_labels, train_diagrams = gen_labels(df_train[:10])\n",
    "val_circuits, val_labels, val_diagrams = gen_labels(df_val[:10])\n",
    "test_circuits, test_labels, test_diagrams = gen_labels(df_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "86c98d2b-33e9-4b5e-98ea-6a96b2d8cb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lambeq.training import BinaryCrossEntropyLoss\n",
    "all_circuits = train_circuits + val_circuits + test_circuits\n",
    "model = NumpyModel.from_diagrams(all_circuits, use_jit=True)\n",
    "loss = BinaryCrossEntropyLoss(use_jax=True)\n",
    "acc = lambda y_hat, y: np.sqrt(np.mean((y_hat-y)**2)/2)\n",
    "eval_metrics = {\"err\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b3072438-8662-426e-9150-4254e1fbcbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(EPOCHS: int, SEED: int, BATCH_SIZE: int) -> None:\n",
    "\n",
    "    trainer = QuantumTrainer(\n",
    "        model,\n",
    "        loss_function=loss,\n",
    "        epochs=EPOCHS,\n",
    "        optimizer=SPSAOptimizer,\n",
    "        optim_hyperparams={'a': 0.1, 'c': 0.06, 'A': 0.01 * EPOCHS},\n",
    "        evaluate_functions=eval_metrics,\n",
    "        evaluate_on_train=True,\n",
    "        verbose='text',\n",
    "        seed=SEED)\n",
    "\n",
    "    train_dataset = Dataset(train_circuits, train_labels, batch_size=BATCH_SIZE)\n",
    "    val_dataset = Dataset(val_circuits, val_labels, shuffle=False)\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    t = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    print(t)\n",
    "    trainer.fit(train_dataset, val_dataset, eval_interval=1, log_interval=1, eval_mode='step')\n",
    "    test_acc = acc(model(test_circuits), test_labels)\n",
    "    print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "672124f2-e3d4-4c38-96d8-d6f81431f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = random.choice([0, 10, 50, 77, 100, 111, 150, 169, 200, 234, 250, 300, 350, 400, 450])\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81041eae-ed8d-4c8e-bfe5-884644557ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02_15_51_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1:    train/loss: 1.0953   valid/loss: 0.8753   train/err: 0.1547   valid/err: 0.1691\n",
      "Step 2:    train/loss: 1.1385   valid/loss: 0.8726   train/err: 0.1631   valid/err: 0.1663\n",
      "Step 3:    train/loss: 1.1453   valid/loss: 0.8760   train/err: 0.1428   valid/err: 0.1297\n",
      "Step 4:    train/loss: 0.9840   valid/loss: 0.8703   train/err: 0.1494   valid/err: 0.1336\n",
      "Step 5:    train/loss: 0.9367   valid/loss: 0.9013   train/err: 0.1567   valid/err: 0.1471\n",
      "Step 6:    train/loss: 0.8575   valid/loss: 0.9530   train/err: 0.1746   valid/err: 0.1565\n",
      "Step 7:    train/loss: 0.8465   valid/loss: 0.9505   train/err: 0.1487   valid/err: 0.1582\n",
      "Step 8:    train/loss: 0.9257   valid/loss: 0.9419   train/err: 0.1588   valid/err: 0.1272\n",
      "Step 9:    train/loss: 0.9050   valid/loss: 1.1418   train/err: 0.1556   valid/err: 0.1526\n",
      "Step 10:   train/loss: 0.8718   valid/loss: 1.1471   train/err: 0.1486   valid/err: 0.1527\n",
      "Step 11:   train/loss: 0.8723   valid/loss: 1.0463   train/err: 0.1492   valid/err: 0.1563\n",
      "Step 12:   train/loss: 0.9121   valid/loss: 1.0600   train/err: 0.1577   valid/err: 0.1525\n",
      "Step 13:   train/loss: 0.8583   valid/loss: 1.0516   train/err: 0.1635   valid/err: 0.1501\n",
      "Step 14:   train/loss: 0.9077   valid/loss: 1.0090   train/err: 0.1486   valid/err: 0.1595\n",
      "Step 15:   train/loss: 0.8515   valid/loss: 0.9902   train/err: 0.1623   valid/err: 0.1584\n",
      "Step 16:   train/loss: 0.8728   valid/loss: 0.9268   train/err: 0.1815   valid/err: 0.1396\n",
      "Step 17:   train/loss: 0.9232   valid/loss: 0.9289   train/err: 0.1544   valid/err: 0.1527\n",
      "Step 18:   train/loss: 0.8316   valid/loss: 0.9177   train/err: 0.1362   valid/err: 0.1443\n",
      "Step 19:   train/loss: 0.8504   valid/loss: 0.9360   train/err: 0.1267   valid/err: 0.1539\n",
      "Step 20:   train/loss: 0.8311   valid/loss: 0.9305   train/err: 0.1415   valid/err: 0.1533\n",
      "Step 21:   train/loss: 0.8237   valid/loss: 0.9319   train/err: 0.1435   valid/err: 0.1537\n",
      "Step 22:   train/loss: 0.8172   valid/loss: 0.9321   train/err: 0.1309   valid/err: 0.1538\n",
      "Step 23:   train/loss: 0.7937   valid/loss: 0.9345   train/err: 0.1498   valid/err: 0.1541\n",
      "Step 24:   train/loss: 0.8122   valid/loss: 0.9336   train/err: 0.1486   valid/err: 0.1540\n",
      "Step 25:   train/loss: 0.8166   valid/loss: 0.9097   train/err: 0.1143   valid/err: 0.1476\n",
      "Step 26:   train/loss: 0.8885   valid/loss: 0.9106   train/err: 0.1316   valid/err: 0.1404\n",
      "Step 27:   train/loss: 0.7847   valid/loss: 0.9029   train/err: 0.1407   valid/err: 0.1429\n",
      "Step 28:   train/loss: 0.8439   valid/loss: 0.9113   train/err: 0.1549   valid/err: 0.1449\n",
      "Step 29:   train/loss: 0.8076   valid/loss: 0.9154   train/err: 0.1579   valid/err: 0.1438\n",
      "Step 30:   train/loss: 0.8855   valid/loss: 0.9436   train/err: 0.1420   valid/err: 0.1439\n",
      "Step 31:   train/loss: 1.0539   valid/loss: 0.9020   train/err: 0.1542   valid/err: 0.1441\n",
      "Step 32:   train/loss: 0.8447   valid/loss: 0.9188   train/err: 0.1439   valid/err: 0.1530\n",
      "Step 33:   train/loss: 0.8309   valid/loss: 0.9201   train/err: 0.1443   valid/err: 0.1532\n",
      "Step 34:   train/loss: 0.8288   valid/loss: 0.9011   train/err: 0.1373   valid/err: 0.1477\n",
      "Step 35:   train/loss: 0.8434   valid/loss: 0.9033   train/err: 0.1512   valid/err: 0.1480\n",
      "Step 36:   train/loss: 0.7881   valid/loss: 0.9018   train/err: 0.1480   valid/err: 0.1467\n",
      "Step 37:   train/loss: 0.8012   valid/loss: 0.9013   train/err: 0.1501   valid/err: 0.1478\n",
      "Step 38:   train/loss: 0.8997   valid/loss: 0.9073   train/err: 0.1559   valid/err: 0.1502\n",
      "Step 39:   train/loss: 0.7843   valid/loss: 0.9071   train/err: 0.1510   valid/err: 0.1492\n",
      "Step 40:   train/loss: 0.9006   valid/loss: 0.9191   train/err: 0.1313   valid/err: 0.1497\n",
      "Step 41:   train/loss: 0.8854   valid/loss: 0.9298   train/err: 0.1197   valid/err: 0.1572\n",
      "Step 42:   train/loss: 0.8849   valid/loss: 0.9319   train/err: 0.1613   valid/err: 0.1522\n",
      "Step 43:   train/loss: 0.8244   valid/loss: 0.9294   train/err: 0.1264   valid/err: 0.1530\n",
      "Step 44:   train/loss: 0.7888   valid/loss: 0.9291   train/err: 0.1512   valid/err: 0.1529\n",
      "Step 45:   train/loss: 0.8412   valid/loss: 0.9282   train/err: 0.1234   valid/err: 0.1526\n",
      "Step 46:   train/loss: 0.8077   valid/loss: 0.9251   train/err: 0.1034   valid/err: 0.1525\n",
      "Step 47:   train/loss: 0.8125   valid/loss: 0.9264   train/err: 0.1222   valid/err: 0.1530\n",
      "Step 48:   train/loss: 0.8543   valid/loss: 0.9410   train/err: 0.1372   valid/err: 0.1518\n",
      "Step 49:   train/loss: 0.8332   valid/loss: 0.9566   train/err: 0.1330   valid/err: 0.1535\n",
      "Step 50:   train/loss: 0.8183   valid/loss: 0.9601   train/err: 0.1260   valid/err: 0.1531\n",
      "Step 51:   train/loss: 0.7895   valid/loss: 0.9589   train/err: 0.1301   valid/err: 0.1537\n",
      "Step 52:   train/loss: 0.9483   valid/loss: 0.9187   train/err: 0.1369   valid/err: 0.1544\n",
      "Step 53:   train/loss: 0.7754   valid/loss: 0.9189   train/err: 0.1312   valid/err: 0.1544\n",
      "Step 54:   train/loss: 0.9176   valid/loss: 0.9306   train/err: 0.1212   valid/err: 0.1503\n",
      "Step 55:   train/loss: 0.7965   valid/loss: 0.9492   train/err: 0.0991   valid/err: 0.1498\n",
      "Step 56:   train/loss: 0.7952   valid/loss: 0.9535   train/err: 0.1292   valid/err: 0.1498\n",
      "Step 57:   train/loss: 0.7931   valid/loss: 0.9421   train/err: 0.1112   valid/err: 0.1486\n",
      "Step 58:   train/loss: 0.8312   valid/loss: 0.9637   train/err: 0.1434   valid/err: 0.1466\n",
      "Step 59:   train/loss: 0.8342   valid/loss: 0.9616   train/err: 0.1519   valid/err: 0.1461\n",
      "Step 60:   train/loss: 0.8512   valid/loss: 0.9563   train/err: 0.1415   valid/err: 0.1461\n",
      "Step 61:   train/loss: 0.8673   valid/loss: 0.9628   train/err: 0.1097   valid/err: 0.1463\n",
      "Step 62:   train/loss: 0.7675   valid/loss: 0.9710   train/err: 0.1254   valid/err: 0.1461\n",
      "Step 63:   train/loss: 0.7673   valid/loss: 0.9609   train/err: 0.1152   valid/err: 0.1478\n",
      "Step 64:   train/loss: 0.7721   valid/loss: 0.9654   train/err: 0.1481   valid/err: 0.1464\n",
      "Step 65:   train/loss: 0.8220   valid/loss: 1.0666   train/err: 0.1398   valid/err: 0.1463\n",
      "Step 66:   train/loss: 0.7876   valid/loss: 0.9814   train/err: 0.1138   valid/err: 0.1454\n",
      "Step 67:   train/loss: 0.7378   valid/loss: 1.0039   train/err: 0.1111   valid/err: 0.1456\n",
      "Step 68:   train/loss: 0.7737   valid/loss: 0.9972   train/err: 0.1318   valid/err: 0.1457\n",
      "Step 69:   train/loss: 0.7784   valid/loss: 1.0222   train/err: 0.1174   valid/err: 0.1445\n",
      "Step 70:   train/loss: 0.7683   valid/loss: 1.0198   train/err: 0.1138   valid/err: 0.1448\n",
      "Step 71:   train/loss: 0.8164   valid/loss: 0.9625   train/err: 0.1401   valid/err: 0.1464\n",
      "Step 72:   train/loss: 0.7596   valid/loss: 0.9604   train/err: 0.1269   valid/err: 0.1465\n",
      "Step 73:   train/loss: 0.7584   valid/loss: 0.9438   train/err: 0.0900   valid/err: 0.1463\n",
      "Step 74:   train/loss: 0.7490   valid/loss: 0.9502   train/err: 0.1010   valid/err: 0.1453\n",
      "Step 75:   train/loss: 0.7896   valid/loss: 0.9554   train/err: 0.1197   valid/err: 0.1452\n",
      "Step 76:   train/loss: 0.7867   valid/loss: 0.9797   train/err: 0.1189   valid/err: 0.1444\n",
      "Step 77:   train/loss: 0.7457   valid/loss: 0.9831   train/err: 0.1137   valid/err: 0.1438\n",
      "Step 78:   train/loss: 0.7396   valid/loss: 0.9943   train/err: 0.1165   valid/err: 0.1436\n",
      "Step 79:   train/loss: 0.7378   valid/loss: 0.9962   train/err: 0.1181   valid/err: 0.1436\n",
      "Step 80:   train/loss: 0.7505   valid/loss: 0.9994   train/err: 0.1051   valid/err: 0.1435\n",
      "Step 81:   train/loss: 0.7826   valid/loss: 0.9932   train/err: 0.1304   valid/err: 0.1435\n",
      "Step 82:   train/loss: 0.7454   valid/loss: 1.0072   train/err: 0.0994   valid/err: 0.1428\n",
      "Step 83:   train/loss: 0.7650   valid/loss: 0.9662   train/err: 0.1371   valid/err: 0.1439\n",
      "Step 84:   train/loss: 0.7705   valid/loss: 0.9763   train/err: 0.1204   valid/err: 0.1442\n",
      "Step 85:   train/loss: 0.7609   valid/loss: 0.9523   train/err: 0.1245   valid/err: 0.1443\n",
      "Step 86:   train/loss: 0.7632   valid/loss: 0.9802   train/err: 0.1305   valid/err: 0.1432\n",
      "Step 87:   train/loss: 0.7436   valid/loss: 0.9874   train/err: 0.0879   valid/err: 0.1432\n",
      "Step 88:   train/loss: 0.7462   valid/loss: 0.9803   train/err: 0.1166   valid/err: 0.1435\n",
      "Step 89:   train/loss: 0.7251   valid/loss: 0.9725   train/err: 0.0949   valid/err: 0.1432\n",
      "Step 90:   train/loss: 0.7308   valid/loss: 0.9953   train/err: 0.0990   valid/err: 0.1434\n",
      "Step 91:   train/loss: 0.7483   valid/loss: 0.9730   train/err: 0.1059   valid/err: 0.1435\n",
      "Step 92:   train/loss: 0.7415   valid/loss: 0.9676   train/err: 0.1139   valid/err: 0.1435\n",
      "Step 93:   train/loss: 0.7685   valid/loss: 0.9402   train/err: 0.1170   valid/err: 0.1435\n",
      "Step 94:   train/loss: 0.7604   valid/loss: 0.9375   train/err: 0.1194   valid/err: 0.1434\n",
      "Step 95:   train/loss: 0.7326   valid/loss: 0.9358   train/err: 0.1020   valid/err: 0.1434\n",
      "Step 96:   train/loss: 0.7476   valid/loss: 0.9347   train/err: 0.1227   valid/err: 0.1434\n",
      "Step 97:   train/loss: 0.7337   valid/loss: 0.9289   train/err: 0.1049   valid/err: 0.1436\n",
      "Step 98:   train/loss: 0.7415   valid/loss: 0.9315   train/err: 0.1181   valid/err: 0.1435\n",
      "Step 99:   train/loss: 0.7999   valid/loss: 0.9525   train/err: 0.1056   valid/err: 0.1429\n",
      "Step 100:  train/loss: 0.7507   valid/loss: 0.9643   train/err: 0.0983   valid/err: 0.1432\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'ArrayImpl' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[126], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(EPOCHS, SEED, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(t)\n\u001b[1;32m     20\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(train_dataset, val_dataset, eval_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, eval_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[43macc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_circuits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n",
      "Cell \u001b[0;32mIn[125], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(y_hat, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m BinaryCrossEntropyLoss(use_jax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#acc = lambda y_hat, y: np.sum(np.equal(np.round(y_hat),y)) / len(y) / 2\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m y_hat, y: np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((\u001b[43my_hat\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43my\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m eval_metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merr\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc}\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/qnlp/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:269\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n\u001b[0;32m--> 269\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported operand type(s) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'ArrayImpl' and 'list'"
     ]
    }
   ],
   "source": [
    "main(EPOCHS, SEED, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00249f2e-75fb-4ba8-9d70-d3a2df0ce387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_emp(diags: [Diagram], model: NumpyModel) -> Model:\n",
    "    scenario = CyclicScenario(['a','b','A','B'],2)\n",
    "    prob_dist = []\n",
    "    for diag in diags:\n",
    "        prob_dist.append(model.get_diagram_output([diag])[0].flatten())\n",
    "    return Model(scenario, prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80177b7-289e-41f7-8b64-afdc81663572",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = NumpyModel.from_checkpoint('runs/Jul02_12-46-52_smew.cs.ucl.ac.uk/best_model.lt')\n",
    "best_model.initialise_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49a519f0-36bb-424e-bcd8-e56729c62193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=n @ n.r @ n @ n) does not compose with diagram 1 (dom=n @ p.r @ n)                                                                 \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "Error: Diagram 0 (cod=) does not compose with diagram 1 (dom=qubit)                                                                                      \n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:48<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "x = df_test[:100]\n",
    "for i, row in tqdm(x.iterrows(), total=len(x)):\n",
    "    try:\n",
    "        s1, s2, p, n = row[['sentence1','sentence2','pronoun','referent']]\n",
    "        diag = ansatz(sent2dig(s1, s2, p, n))\n",
    "        \n",
    "        diagXX = diag.apply_gate(Ry(0),0)\n",
    "        diagXX = diagXX.apply_gate(Ry(np.pi/8),1)\n",
    "        \n",
    "        diagXZ = diag.apply_gate(Ry(0),0)\n",
    "        diagXZ = diagXZ.apply_gate(Ry(3*np.pi/8),1)\n",
    "        \n",
    "        diagZX = diag.apply_gate(Ry(np.pi/4),0)\n",
    "        diagZX = diagZX.apply_gate(Ry(np.pi/8),1)\n",
    "        \n",
    "        diagZZ = diag.apply_gate(Ry(np.pi/4),0)\n",
    "        diagZZ = diagZZ.apply_gate(Ry(3*np.pi/8),1)\n",
    "        \n",
    "        emp_model = gen_emp([diagXX, diagXZ, diagZX, diagZZ], best_model)\n",
    "        \n",
    "        # res.append((emp_model.contextual_fraction(),\n",
    "        #               emp_model.signalling_fraction(),\n",
    "        #               emp_model.CbD_direct_influence(),\n",
    "        #               emp_model.CbD_measure()))\n",
    "        res.append(emp_model)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error: {e}\".strip(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58182f4f-a65c-41b8-98eb-11a27085d710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x, y = [], []\n",
    "for mod in res:\n",
    "    x.append(mod.signalling_fraction())\n",
    "    y.append(mod.CbD_direct_influence())\n",
    "plt.scatter(x, y)\n",
    "plt.axhline(y=2, color='g', linestyle='-')\n",
    "plt.axvline(x=1/6, color='g', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ca08d-d811-4182-b35e-f5f3c85fcf67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnlp",
   "language": "python",
   "name": "qnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
